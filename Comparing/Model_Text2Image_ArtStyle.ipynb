{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYsJH_0g0BFb"
      },
      "outputs": [],
      "source": [
        "# Install the different libraries\n",
        "!pip install dalle-pytorch --upgrade\n",
        "!pip install gdown\n",
        "!git clone https://github.com/lucidrains/DALLE-pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect the google drive repo\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "o2ngBULNRH09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coco Dataset\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "# Set paths for the coco dataset\n",
        "dataDir='/content/drive/MyDrive/COCOdataset2017Airplanes'\n",
        "dataType='train2017'\n",
        "annFile='{}/annotations/instances_{}.json'.format(dataDir,dataType)"
      ],
      "metadata": {
        "id": "ZiR9d69tTaNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the COCO api for instance annotations\n",
        "coco=COCO(annFile)\n",
        "\n",
        "# Load the categories in a variable\n",
        "catIDs = coco.getCatIds()\n",
        "cats = coco.loadCats(catIDs)\n",
        "\n",
        "# Define the classes (out of the 81) which you want to see. Others will not be shown.\n",
        "filterClasses = ['airplane']\n",
        "\n",
        "# Fetch class IDs only corresponding to the filterClasses\n",
        "catIds = coco.getCatIds(catNms=filterClasses) \n",
        "# Get all images containing the above Category IDs\n",
        "imgIds = coco.getImgIds(catIds=catIds)\n",
        "\n",
        "# initialize COCO API for caption captions\n",
        "captions_annFile = '{}/annotations/captions_{}_planes.json'.format(dataDir,dataType)\n",
        "coco_caps = COCO(captions_annFile)"
      ],
      "metadata": {
        "id": "YDSfQXrmTt-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists to contain the images info\n",
        "images_annot = []\n",
        "images_paths = []\n",
        "\n",
        "for i in range(2586, 2985):\n",
        "  # Training set from 0 to 1999\n",
        "  # Validation set from 2000 to 2585\n",
        "  # Test set from 2586 to 2985\n",
        "  \n",
        "  annIds = coco_caps.getAnnIds(imgIds=imgIds[i])\n",
        "  anns = coco_caps.loadAnns(annIds)\n",
        "\n",
        "  # Keep the captions\n",
        "  images_annot.append(anns[0]['caption'])\n",
        "\n",
        "  #Get file paths\n",
        "  img=coco.loadImgs(imgIds[i])[0]\n",
        "  content_img_path='{}/New_Art_Airplanes_Final/{}'.format(dataDir,img['file_name'])\n",
        "\n",
        "  # Keep the path\n",
        "  images_paths.append(content_img_path)"
      ],
      "metadata": {
        "id": "SkAopgbEUsTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take of the \"'\" of the captions to limit errors\n",
        "images_annot_v2 = []\n",
        "for el in images_annot:\n",
        "  images_annot_v2.append(el.replace(\"'\", \" \"))"
      ],
      "metadata": {
        "id": "5Cv0O80JDGRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables containing the distances\n",
        "distanceTotal = 0\n",
        "distances_list = []\n",
        "\n",
        "# import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "for i in range(0,400):\n",
        "\n",
        "  # Get the current caption\n",
        "  CAPTION = images_annot_v2[i]\n",
        "\n",
        "  # Use the dalle model given some parameters like the caption\n",
        "  # returns an image describing the caption with an art style\n",
        "  !python /content/DALLE-pytorch/generate.py --dalle_path /content/drive/MyDrive/WandB/dalle_Dim12.pt --text '{CAPTION}' --batch_size 1 --num_images 1\n",
        "\n",
        "  # Use DeepAI API to get similarity between two images\n",
        "  r = requests.post(\n",
        "      \"https://api.deepai.org/api/image-similarity\",\n",
        "      files={\n",
        "          'image1': open('/content/outputs/' + images_annot_v2[i].replace(' ', '_') + '/0.jpg', 'rb'),\n",
        "          'image2': open(images_paths[i], 'rb'),\n",
        "      },\n",
        "      headers={'api-key': '##API-KEY##'}\n",
        "  )\n",
        "\n",
        "  # Handle returned request and get distance from it\n",
        "  distance = r.json()['output']['distance']\n",
        "  distanceTotal += distance\n",
        "  distances_list.append(distance)\n",
        "\n",
        "  # Back-up of the current progress under a CSV file saved directly in the\n",
        "  # Drive\n",
        "  if (i % 10) == 0:\n",
        "    df = pd.DataFrame(distances_list)\n",
        "    df.to_csv('/content/drive/MyDrive/Results_text2image/dim12_'+ str(i) + '.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "t5QngK3ZfiJF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "e7d6e62d90e7e85f9a0faa7f0b1d576302d7ae6108e9fe361594f8e1c8b05781"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU",
    "colab": {
      "name": "v2_Text2Im2ArtStyle.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
